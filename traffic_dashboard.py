"""
Traffic Dashboard â€” Live overlays + Streamlit metrics
Features:
- YOLOv8 detection
- Vehicle tracking with CentroidTracker
- Bounding box width/height shrinking to match vehicle shape
- Live on-video dashboard: total vehicles, counts by type, speed violations
- Speed estimation (optional ppm calibration)
- Annotated video saved and downloadable

NOTE: Detection parameters (confidence, processing width, speed limit) are
hardcoded for a clean UI experience.
"""

import streamlit as st
import cv2
import tempfile
import time
import os
import numpy as np
from ultralytics import YOLO
from math import sqrt

# ---------------------------
# Centroid Tracker (No change needed)
# ---------------------------
class CentroidTracker:
Â  Â  def __init__(self, max_distance=60, max_disappeared=30):
Â  Â  Â  Â  self.next_object_id = 1
Â  Â  Â  Â  self.objects = {}
Â  Â  Â  Â  self.disappeared = {}
Â  Â  Â  Â  self.max_distance = max_distance
Â  Â  Â  Â  self.max_disappeared = max_disappeared

Â  Â  def register(self, centroid):
Â  Â  Â  Â  oid = self.next_object_id
Â  Â  Â  Â  self.next_object_id += 1
Â  Â  Â  Â  self.objects[oid] = centroid
Â  Â  Â  Â  self.disappeared[oid] = 0
Â  Â  Â  Â  return oid

Â  Â  def deregister(self, oid):
Â  Â  Â  Â  self.objects.pop(oid, None)
Â  Â  Â  Â  self.disappeared.pop(oid, None)

Â  Â  def update(self, rects):
Â  Â  Â  Â  input_centroids = []
Â  Â  Â  Â  for (x1, y1, x2, y2, cls_name) in rects:
Â  Â  Â  Â  Â  Â  cX = int((x1 + x2) / 2.0)
Â  Â  Â  Â  Â  Â  cY = int((y1 + y2) / 2.0)
Â  Â  Â  Â  Â  Â  input_centroids.append((cX, cY, x1, y1, x2, y2, cls_name))

Â  Â  Â  Â  if len(self.objects) == 0:
Â  Â  Â  Â  Â  Â  outputs = []
Â  Â  Â  Â  Â  Â  for cent in input_centroids:
Â  Â  Â  Â  Â  Â  Â  Â  oid = self.register((cent[0], cent[1]))
Â  Â  Â  Â  Â  Â  Â  Â  outputs.append((oid, cent[2], cent[3], cent[4], cent[5], cent[6]))
Â  Â  Â  Â  Â  Â  return outputs

Â  Â  Â  Â  object_ids = list(self.objects.keys())
Â  Â  Â  Â  object_centroids = [self.objects[oid] for oid in object_ids]

Â  Â  Â  Â  D = np.zeros((len(object_centroids), len(input_centroids)), dtype="float")
Â  Â  Â  Â  for i, oc in enumerate(object_centroids):
Â  Â  Â  Â  Â  Â  for j, ic in enumerate(input_centroids):
Â  Â  Â  Â  Â  Â  Â  Â  # Calculate Euclidean distance between centroids
Â  Â  Â  Â  Â  Â  Â  Â  D[i, j] = sqrt((oc[0] - ic[0])**2 + (oc[1] - ic[1])**2)

Â  Â  Â  Â  # Find the smallest distances and sort by row index
Â  Â  Â  Â  rows = D.min(axis=1).argsort()
Â  Â  Â  Â  # Find the column index corresponding to the minimum distance for each row
Â  Â  Â  Â  cols = D.argmin(axis=1)[rows]

Â  Â  Â  Â  assigned_rows, assigned_cols = set(), set()
Â  Â  Â  Â  outputs = []

Â  Â  Â  Â  for row, col in zip(rows, cols):
Â  Â  Â  Â  Â  Â  if row in assigned_rows or col in assigned_cols:
Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  if D[row, col] > self.max_distance:
Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Assignment successful
Â  Â  Â  Â  Â  Â  oid = object_ids[row]
Â  Â  Â  Â  Â  Â  ic = input_centroids[col]
Â  Â  Â  Â  Â  Â  self.objects[oid] = (ic[0], ic[1]) # Update object centroid
Â  Â  Â  Â  Â  Â  self.disappeared[oid] = 0 # Reset disappearance counter
Â  Â  Â  Â  Â  Â  outputs.append((oid, ic[2], ic[3], ic[4], ic[5], ic[6]))
Â  Â  Â  Â  Â  Â  assigned_rows.add(row)
Â  Â  Â  Â  Â  Â  assigned_cols.add(col)

Â  Â  Â  Â  # Handle unassigned objects (they have disappeared)
Â  Â  Â  Â  unassigned_rows = set(range(0, D.shape[0])) - assigned_rows
Â  Â  Â  Â  for row in unassigned_rows:
Â  Â  Â  Â  Â  Â  oid = object_ids[row]
Â  Â  Â  Â  Â  Â  self.disappeared[oid] += 1
Â  Â  Â  Â  Â  Â  if self.disappeared[oid] > self.max_disappeared:
Â  Â  Â  Â  Â  Â  Â  Â  self.deregister(oid)

Â  Â  Â  Â  # Handle unassigned new detections (register them)
Â  Â  Â  Â  unassigned_cols = set(range(0, D.shape[1])) - assigned_cols
Â  Â  Â  Â  for col in unassigned_cols:
Â  Â  Â  Â  Â  Â  ic = input_centroids[col]
Â  Â  Â  Â  Â  Â  oid = self.register((ic[0], ic[1]))
Â  Â  Â  Â  Â  Â  outputs.append((oid, ic[2], ic[3], ic[4], ic[5], ic[6]))

Â  Â  Â  Â  return outputs

# ---------------------------
# Helpers
# ---------------------------
# Map COCO class IDs to vehicle names
COCO_VEHICLE_MAP = {2: "car", 3: "motorcycle", 5: "bus", 7: "truck", 1: "bicycle"}

# Factors to shrink the bounding box width/height for tighter fit
# Format: (width_factor, height_factor)
SHRINK_FACTORS = {
Â  Â  "car": (0.8, 0.85),
Â  Â  "motorcycle": (0.7, 0.7),
Â  Â  "bus": (0.9, 0.9),
Â  Â  "truck": (0.85, 0.9),
Â  Â  "bicycle": (0.6, 0.6),
Â  Â  "other": (0.7, 0.7)
}

def clamp(v, lo, hi):
Â  Â  """Clamps a value within a given range."""
Â  Â  return max(lo, min(hi, v))

def estimate_speed_pixels(prev_center, prev_time, cur_center, cur_time, ppm=None):
Â  Â  """
Â  Â  Estimates speed based on pixel movement over time.
Â  Â  Returns speed in km/h.
Â  Â  """
Â  Â  dt = cur_time - prev_time
Â  Â  if dt <= 0: return 0.0
Â  Â Â 
Â  Â  dx = cur_center[0] - prev_center[0]
Â  Â  dy = cur_center[1] - prev_center[1]
Â  Â  pix_distance = sqrt(dx*dx + dy*dy)
Â  Â Â 
Â  Â  # Using a placeholder conversion (0.02 meters/pixel) for demonstration
Â  Â  meters = pix_distance * 0.02 if ppm is None else pix_distance / ppmÂ 
Â  Â Â 
Â  Â  # Convert m/s to km/h (m/s * 3.6)
Â  Â  return meters / dt * 3.6

def draw_dashboard(frame, records, overspeed_ids, width):
Â  Â  """Draws a semi-transparent dashboard at the top of the video."""
Â  Â  overlay = frame.copy()
Â  Â Â 
Â  Â  # Dashboard background
Â  Â  cv2.rectangle(overlay, (0, 0), (width, 85), (0, 0, 0), -1)
Â  Â  alpha = 0.7
Â  Â  cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)
Â  Â Â 
Â  Â  # Calculate stats
Â  Â  total_vehicles = len(records)
Â  Â  vehicle_types = [r['type'] for r in records.values()]
Â  Â  n_cars = vehicle_types.count("car")
Â  Â  n_trucks = vehicle_types.count("truck")
Â  Â  n_buses = vehicle_types.count("bus")
Â  Â  n_bikes = vehicle_types.count("motorcycle") + vehicle_types.count("bicycle")
Â  Â  n_violations = len(overspeed_ids)
Â  Â Â 
Â  Â  # Draw Text Stats
Â  Â  font = cv2.FONT_HERSHEY_SIMPLEX
Â  Â  white = (255, 255, 255)
Â  Â  yellow = (0, 255, 255)
Â  Â  red = (0, 0, 255)
Â  Â Â 
Â  Â  # Row 1: Title & Total
Â  Â  cv2.putText(frame, "TRAFFIC MONITORING SYSTEM", (20, 30), font, 0.7, yellow, 2)
Â  Â  cv2.putText(frame, f"TOTAL: {total_vehicles}", (width - 150, 30), font, 0.7, white, 2)
Â  Â Â 
Â  Â  # Row 2: Type Counts
Â  Â  stats_text = f"Car: {n_cars} | Truck: {n_trucks} | Bus: {n_buses} | Bike: {n_bikes}"
Â  Â  cv2.putText(frame, stats_text, (20, 65), font, 0.55, white, 1)
Â  Â Â 
Â  Â  # Row 2 Right: Violations
Â  Â  viol_text = f"VIOLATIONS: {n_violations}"
Â  Â  cv2.putText(frame, viol_text, (width - 200, 65), font, 0.55, red, 2)

# ---------------------------
# Streamlit UI
# ---------------------------
st.set_page_config(layout="wide")
st.title("ğŸš¦ Smart Traffic Analyzer")
st.markdown("Automated vehicle classification, tracking, and speed enforcement.")


# --- HARDCODED ANALYSIS PARAMETERS ---
min_conf = 0.35Â  Â  Â  # Default minimum detection confidence
process_width = 640Â  # Default width for faster processing
speed_limit = 60Â  Â  Â # Default speed limit in km/h
# -------------------------------------


# Minimal Sidebar UI
with st.sidebar:
Â  Â  st.header("Control Panel")
Â  Â  uploaded = st.file_uploader("Upload Video File", type=["mp4","avi","mov"])
Â  Â  start_btn = st.button("Start Analysis")
Â  Â  st.markdown("---")
Â  Â  st.info(f"Speed Limit set to **{speed_limit} km/h**")


tracker = CentroidTracker(max_distance=60)

@st.cache_resource
def load_yolo_model():Â 
Â  Â  """Loads the YOLOv8n model once."""
Â  Â  return YOLO("yolov8n.pt")

yolo = load_yolo_model()

# Placeholders for the video display
video_placeholder = st.empty()

if uploaded and start_btn:
Â  Â  # Setup temporary file and video capture/writer
Â  Â  tmp = tempfile.NamedTemporaryFile(delete=False,suffix=os.path.splitext(uploaded.name)[1])
Â  Â  tmp.write(uploaded.read()); tmp.flush()
Â  Â  cap = cv2.VideoCapture(tmp.name)
Â  Â  fps = cap.get(cv2.CAP_PROP_FPS) or 20.0
Â  Â  frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)
Â  Â  width,height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
Â  Â  out_path = os.path.join(tempfile.gettempdir(),f"processed_traffic_{int(time.time())}.mp4")
Â  Â  writer = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc(*"mp4v"),fps,(width,height))

Â  Â  # Tracking and metrics variables
Â  Â  records,last_centers,seen_ids,overspeed_ids = {},{},set(),set()

Â  Â  st.success("Initializing analysis engine...")
Â  Â  progress_bar = st.progress(0)
Â  Â  frame_idx = 0

Â  Â  while True:
Â  Â  Â  Â  ret,frame = cap.read()
Â  Â  Â  Â  if not ret: break
Â  Â  Â  Â Â 
Â  Â  Â  Â  frame_idx += 1
Â  Â  Â  Â  if frame_count > 0:
Â  Â  Â  Â  Â  Â  progress_bar.progress(frame_idx / frame_count)

Â  Â  Â  Â  # Resize for faster processing logic (inference)
Â  Â  Â  Â  h0,w0 = frame.shape[:2]
Â  Â  Â  Â  scale = process_width/float(w0)
Â  Â  Â  Â  small = cv2.resize(frame,(process_width,int(h0*scale)))
Â  Â  Â  Â  rgb = small[:,:,::-1]

Â  Â  Â  Â  # YOLOv8 Prediction
Â  Â  Â  Â  results = yolo.predict(rgb,imgsz=process_width,conf=min_conf,verbose=False)
Â  Â  Â  Â  detections = []
Â  Â  Â  Â Â 
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  res = results[0]
Â  Â  Â  Â  Â  Â  if hasattr(res,"boxes") and res.boxes is not None:
Â  Â  Â  Â  Â  Â  Â  Â  boxes = res.boxes.xyxy.cpu().numpy()
Â  Â  Â  Â  Â  Â  Â  Â  classes = res.boxes.cls.cpu().numpy()
Â  Â  Â  Â  Â  Â  Â  Â  scores = res.boxes.conf.cpu().numpy()
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  for (x1_s,y1_s,x2_s,y2_s),cls_id,conf in zip(boxes,classes,scores):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if conf<min_conf: continue
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Rescale coordinates back to original frame size
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x1_o=int(x1_s/scale); y1_o=int(y1_s/scale)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x2_o=int(x2_s/scale); y2_o=int(y2_s/scale)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cls_name=COCO_VEHICLE_MAP.get(int(cls_id),"other")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  w_factor, h_factor = SHRINK_FACTORS.get(cls_name, (0.7, 0.7))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Apply bounding box shrinking for both Width and Height
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cx=(x1_o+x2_o)//2
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cy=(y1_o+y2_o)//2
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  orig_w = x2_o - x1_o
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  orig_h = y2_o - y1_o
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_w = int(orig_w * w_factor)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_h = int(orig_h * h_factor)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Clamp coordinates to frame boundaries
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x1_new=clamp(cx-new_w//2,0,width-1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x2_new=clamp(cx+new_w//2,0,width-1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y1_new=clamp(cy-new_h//2,0,height-1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y2_new=clamp(cy+new_h//2,0,height-1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if x2_new<=x1_new: x2_new=x1_new+1
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if y2_new<=y1_new: y2_new=y1_new+1
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  detections.append((x1_new,y1_new,x2_new,y2_new,cls_name))
Â  Â  Â  Â  except Exception:Â 
Â  Â  Â  Â  Â  Â  Â pass

Â  Â  Â  Â  # Centroid Tracking Update
Â  Â  Â  Â  tracked=tracker.update(detections)
Â  Â  Â  Â  current_frame_time = time.time()
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Process tracked objects
Â  Â  Â  Â  for tid,x1,y1,x2,y2,cls_name in tracked:
Â  Â  Â  Â  Â  Â  cx=(x1+x2)//2; cy=(y1+y2)//2
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if tid not in records:Â 
Â  Â  Â  Â  Â  Â  Â  Â  records[tid]={"type":cls_name,"max_speed":0.0,"violations":set()}
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Speed Estimation
Â  Â  Â  Â  Â  Â  if tid in last_centers:
Â  Â  Â  Â  Â  Â  Â  Â  (prev_cx,prev_cy),prev_t = last_centers[tid]
Â  Â  Â  Â  Â  Â  Â  Â  speed_kmh = estimate_speed_pixels((prev_cx,prev_cy),prev_t,(cx,cy),current_frame_time)
Â  Â  Â  Â  Â  Â  else:Â 
Â  Â  Â  Â  Â  Â  Â  Â  speed_kmh=0.0
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  last_centers[tid]=((cx,cy),current_frame_time)
Â  Â  Â  Â  Â  Â  records[tid]["max_speed"]=max(records[tid]["max_speed"],speed_kmh)
Â  Â  Â  Â  Â  Â  seen_ids.add(tid)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Violation Check
Â  Â  Â  Â  Â  Â  is_overspeed = speed_kmh > speed_limit
Â  Â  Â  Â  Â  Â  if is_overspeed:
Â  Â  Â  Â  Â  Â  Â  Â  records[tid]["violations"].add("overspeed")
Â  Â  Â  Â  Â  Â  Â  Â  overspeed_ids.add(tid)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Visualization ---
Â  Â  Â  Â  Â  Â  has_violation = len(records[tid]["violations"]) > 0
Â  Â  Â  Â  Â  Â  box_color = (0, 0, 255) if has_violation else (0, 255, 0)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # 1. Bounding Box
Â  Â  Â  Â  Â  Â  cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # 2. Label Background (for better readability)
Â  Â  Â  Â  Â  Â  label = f"ID:{tid} {cls_name.upper()}"
Â  Â  Â  Â  Â  Â  (w_text, h_text), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
Â  Â  Â  Â  Â  Â  cv2.rectangle(frame, (x1, y1 - 20), (x1 + w_text, y1), box_color, -1)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # 3. Label Text
Â  Â  Â  Â  Â  Â  cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # 4. Speed Text
Â  Â  Â  Â  Â  Â  speed_text = f"{speed_kmh:.1f} km/h"
Â  Â  Â  Â  Â  Â  cv2.putText(frame, speed_text, (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if is_overspeed:
Â  Â  Â  Â  Â  Â  Â  Â  Â cv2.putText(frame, "SPEED LIMIT!", (x1, y1 - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

Â  Â  Â  Â  # Draw the Dashboard on Top
Â  Â  Â  Â  draw_dashboard(frame, records, overspeed_ids, width)

Â  Â  Â  Â  writer.write(frame)
Â  Â  Â  Â  video_placeholder.image(frame[:,:,::-1],caption=f"Processing Frame {frame_idx}",use_column_width=True)

Â  Â  cap.release()
Â  Â  writer.release()
Â  Â  progress_bar.progress(1.0)
Â  Â Â 
Â  Â  st.success("Analysis Complete!")
Â  Â Â 
Â  Â  # Download Button
Â  Â  with open(out_path,"rb") as f:
Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  label="â¬‡ï¸ Download Processed Video",
Â  Â  Â  Â  Â  Â  data=f.read(),
Â  Â  Â  Â  Â  Â  file_name="traffic_analysis_output.mp4",
Â  Â  Â  Â  Â  Â  mime="video/mp4"
Â  Â  Â  Â  )
Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  os.unlink(tmp.name)
Â  Â  Â  Â  os.unlink(out_path)
Â  Â  except Exception:
Â  Â  Â  Â  pass

else:Â 
Â  Â  st.info("Upload a video to begin analysis.")
Â  Â  st.write("The processed video will include an on-screen dashboard with vehicle counts and speed alerts.") 
